---
title: "732A95tenta"
author: "Mitt tentainlogg"
date: "4 January 2017"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Assignment 1 

## 1.1 

```{r}
glass <- read.csv2("glass.csv")

set.seed(12345)
glass <- glass[sample(nrow(glass), replace = FALSE),] 

train <- glass[1:107,]
test  <- glass[108:(108+53),]
valid  <- glass[(108+54):214,]

library(tree)


glass.tree <- tree(formula = Al ~ ., data = train, split = "deviance" )  
plot(glass.tree)
no.leafs <- data.frame(trainS=1,testS = 1)
rad <- 1 

for (i in 2:8) {  
  pruned.glass    <-  prune.tree(glass.tree, best = i)
   no.leafs[rad,1] <-  mean( (train$Al - predict(pruned.glass))^2 )
   no.leafs[rad,2] <-   mean((valid$Al - predict( pruned.glass , newdata = valid, type = "vector"))^2)
  #  
   # no.leafs[rad,1] <-  deviance( pruned.glass )
   # no.leafs[rad,2] <-  2 * deviance(predict( pruned.glass , newdata = valid, type = "tree"))
  rad <- rad + 1 
}


library(ggplot2)


ggplot(data = no.leafs) + geom_line(aes(x = 1:7, y = trainS),color = "blue") +
  geom_line(aes(x = 1:7, y = testS),color = "red") + labs(x="number of leafs" ,y = "MSE")

```

The optimal number of leafs in the regression tree is three since it gives the lowest Validation error (red line). The blue line represents the MSE for the training data set and the line seems to decrese very slowly when the number of leafs are increased. Meanwhile the  validation error decreses in the begining but then increases. This is the bias -variance trade off because we continue to try to minimize the MSE for the training set the model becomes overfitted and loses its predictive power since it becomes less general and more specific to the data.

# 1.2 


```{r}

best.glass <- prune.tree(glass.tree, best = 3)
plot(best.glass)
text(best.glass)

testerror <-  mean( ( predict(pruned.glass,newdata = test) - test$Al )^2 )
print(paste("The test error was calculated to:",testerror))
```

The chosen variables are K and Ca, im to bad at chemistry to remember what they represent but 

## 1.3 


### a)
```{r}
library(pls)
myplsr <- plsr(formula = Al ~ ., data = train, validation  = c("CV") )

summary(myplsr)
```

One would need 3 components to explain over 90 % of the variation in the feature-space
### b)

### c) 

```{r}
myplsr$validation$PRESS
```

All 7 components are needed according to the PRESS since 7 comps has the lowest value.

### d) 

### e)
```{r}
myplsr$coefficients
```

### f)
```{r}
mean((test$Al - predict(myplsr, newdata = test))^2)
```


## 1.4

The PLSR have a lower test-error and therefor have a better predictive power. Because we want to estimate the prediction power of the model one observation is a very small sample and is probably similar to the training set so that it would have a high variance. 


# Assignment 2 



